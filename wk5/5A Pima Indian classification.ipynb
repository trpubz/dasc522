{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5A Pima Indian classification.ipynb","provenance":[],"authorship_tag":"ABX9TyM/BCdS/ulrTvLNNqGQXVf8"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"E0PrzAyM62ro"},"source":["Preamble & DU"]},{"cell_type":"code","metadata":{"id":"MrbsR3QOyWl0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610753678118,"user_tz":600,"elapsed":2300,"user":{"displayName":"Torrey Wagner","photoUrl":"","userId":"18235062716651285949"}},"outputId":"b55ea42b-9982-4ccb-d2d9-fba1b079567f"},"source":["from numpy import loadtxt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","import time\n","\n","# load the dataset\n","dataset = loadtxt('5A pima-indians-diabetes.data.csv', delimiter=',')\n","\n","# split into input (X) and output (y) variables\n","X = dataset[:,0:7]\n","y = dataset[:,8]\n","\n","dataset"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n","       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n","       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n","       ...,\n","       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n","       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n","       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"iTgjM-oi6vGV"},"source":["Create NN"]},{"cell_type":"code","metadata":{"id":"dEnylyU76xZr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610753684799,"user_tz":600,"elapsed":8975,"user":{"displayName":"Torrey Wagner","photoUrl":"","userId":"18235062716651285949"}},"outputId":"1ebd12f2-1487-485e-800b-0338500a4070"},"source":["# define the keras model\n","model = Sequential()\n","model.add(Dense(12, input_dim=7, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# compile the keras model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# fit the keras model on the dataset\n","startTime = time.time()\n","\n","model.fit(X, y, epochs=45, batch_size=10)\n","\n","endTime = time.time()-startTime\n","print(\"elasped time \" + str(endTime))\n","\n","# evaluate the keras model\n","_, accuracy = model.evaluate(X, y)\n","\n","print('\\n Final Accuracy: %.2f' % (accuracy*100))\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Epoch 1/45\n","77/77 [==============================] - 1s 1ms/step - loss: 9.6534 - accuracy: 0.3487\n","Epoch 2/45\n","77/77 [==============================] - 0s 1ms/step - loss: 2.7668 - accuracy: 0.4986\n","Epoch 3/45\n","77/77 [==============================] - 0s 1ms/step - loss: 1.1774 - accuracy: 0.5576\n","Epoch 4/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.7579 - accuracy: 0.6423\n","Epoch 5/45\n","77/77 [==============================] - 0s 2ms/step - loss: 0.7281 - accuracy: 0.6137\n","Epoch 6/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.6469\n","Epoch 7/45\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.6375\n","Epoch 8/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.6534\n","Epoch 9/45\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6904\n","Epoch 10/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6679\n","Epoch 11/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6719\n","Epoch 12/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.7001\n","Epoch 13/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.6721\n","Epoch 14/45\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.6511\n","Epoch 15/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6448 - accuracy: 0.6696\n","Epoch 16/45\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.6690\n","Epoch 17/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5867 - accuracy: 0.7119\n","Epoch 18/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.6814\n","Epoch 19/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6461 - accuracy: 0.6987\n","Epoch 20/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.7104\n","Epoch 21/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.7121\n","Epoch 22/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6098 - accuracy: 0.7003\n","Epoch 23/45\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.6949\n","Epoch 24/45\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.6773\n","Epoch 25/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.6977\n","Epoch 26/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.6671\n","Epoch 27/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.7087\n","Epoch 28/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 0.7207\n","Epoch 29/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.6816\n","Epoch 30/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5977 - accuracy: 0.6728\n","Epoch 31/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.7024\n","Epoch 32/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5889 - accuracy: 0.7334\n","Epoch 33/45\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7157\n","Epoch 34/45\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7007\n","Epoch 35/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.7129\n","Epoch 36/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7241\n","Epoch 37/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.7125\n","Epoch 38/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5593 - accuracy: 0.6915\n","Epoch 39/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7199\n","Epoch 40/45\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7209\n","Epoch 41/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5996 - accuracy: 0.7062\n","Epoch 42/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.6949\n","Epoch 43/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7284\n","Epoch 44/45\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.7138\n","Epoch 45/45\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7226\n","elasped time 6.133798122406006\n","24/24 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7096\n","\n"," Final Accuracy: 70.96\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7CqaTcIo6ySL"},"source":["Visualize NN - text"]},{"cell_type":"code","metadata":{"id":"BM5BUqH06zdK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610753684799,"user_tz":600,"elapsed":8973,"user":{"displayName":"Torrey Wagner","photoUrl":"","userId":"18235062716651285949"}},"outputId":"6040b757-e483-453a-9478-73d296980e7e"},"source":["model.summary()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 12)                96        \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 8)                 104       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 9         \n","=================================================================\n","Total params: 209\n","Trainable params: 209\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v2gzNhXHAr6M"},"source":["Visualize NN - graphical"]},{"cell_type":"code","metadata":{"id":"VQniyQUkAyKj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610753690722,"user_tz":600,"elapsed":14894,"user":{"displayName":"Torrey Wagner","photoUrl":"","userId":"18235062716651285949"}},"outputId":"19ddd55b-e67f-4fd8-c353-30759421c253"},"source":["# create visualization\n","!pip3 install ann_visualizer\n","\n","from ann_visualizer.visualize import ann_viz;\n","\n","ann_viz(model, title=\"Pima Indian Diabetes Dataset NN\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting ann_visualizer\n","  Downloading https://files.pythonhosted.org/packages/db/51/157be500337fba347e32711aaf9f11c1ba9e1162f486a1d708b4ae594ea4/ann_visualizer-2.5.tar.gz\n","Building wheels for collected packages: ann-visualizer\n","  Building wheel for ann-visualizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ann-visualizer: filename=ann_visualizer-2.5-cp36-none-any.whl size=4169 sha256=e263cd86d47da5977cee40ad2bdeb549adc72422300f28f87f434cc4a4a08ba5\n","  Stored in directory: /root/.cache/pip/wheels/b6/b4/4e/d92f50c9c4f004cf315a0e0fcd455486bd799c50fe80cf1f5d\n","Successfully built ann-visualizer\n","Installing collected packages: ann-visualizer\n","Successfully installed ann-visualizer-2.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"imr6l6nW_3IJ"},"source":["Overfit the data"]},{"cell_type":"code","metadata":{"id":"zQFnr525_4ZI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610753703807,"user_tz":600,"elapsed":27978,"user":{"displayName":"Torrey Wagner","photoUrl":"","userId":"18235062716651285949"}},"outputId":"4fdef8b6-fa49-48fe-c43c-2e66640c4a6d"},"source":["# define the keras model\n","model = Sequential()\n","model.add(Dense(20, input_dim=7, activation='relu'))\n","model.add(Dense(20, activation='relu'))\n","model.add(Dense(20, activation='sigmoid'))\n","model.add(Dense(20, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# compile the keras model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# fit the keras model on the dataset\n","startTime = time.time()\n","\n","model.fit(X, y, epochs=100, batch_size=10)\n","\n","endTime = time.time()-startTime\n","print(\"elasped time \" + str(endTime))\n","\n","# evaluate the keras model\n","_, accuracy = model.evaluate(X, y)\n","\n","print('\\n Final Accuracy: %.2f' % (accuracy*100))\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","77/77 [==============================] - 1s 1ms/step - loss: 0.6590 - accuracy: 0.6364\n","Epoch 2/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6537\n","Epoch 3/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6173 - accuracy: 0.6539\n","Epoch 4/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6370\n","Epoch 5/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6125 - accuracy: 0.6558\n","Epoch 6/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6184 - accuracy: 0.6426\n","Epoch 7/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6032 - accuracy: 0.6521\n","Epoch 8/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.6988\n","Epoch 9/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6731\n","Epoch 10/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5894 - accuracy: 0.6701\n","Epoch 11/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.6746\n","Epoch 12/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6548\n","Epoch 13/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5965 - accuracy: 0.6921\n","Epoch 14/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.6813\n","Epoch 15/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.6647\n","Epoch 16/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7028\n","Epoch 17/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5823 - accuracy: 0.6903\n","Epoch 18/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.6717\n","Epoch 19/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5693 - accuracy: 0.6914\n","Epoch 20/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6288 - accuracy: 0.5991\n","Epoch 21/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.6657\n","Epoch 22/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.6861\n","Epoch 23/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.6542\n","Epoch 24/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6820\n","Epoch 25/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5889 - accuracy: 0.6801\n","Epoch 26/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6106 - accuracy: 0.6428\n","Epoch 27/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.6770\n","Epoch 28/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 0.6806\n","Epoch 29/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6080 - accuracy: 0.6499\n","Epoch 30/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.6856\n","Epoch 31/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.6948\n","Epoch 32/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.6853\n","Epoch 33/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.7033\n","Epoch 34/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7219\n","Epoch 35/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6578\n","Epoch 36/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5554 - accuracy: 0.6983\n","Epoch 37/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.6875\n","Epoch 38/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5605 - accuracy: 0.7260\n","Epoch 39/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5420 - accuracy: 0.7352\n","Epoch 40/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6248\n","Epoch 41/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7270\n","Epoch 42/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.6909\n","Epoch 43/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.6852\n","Epoch 44/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.6073 - accuracy: 0.6223\n","Epoch 45/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6815\n","Epoch 46/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.6640\n","Epoch 47/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.6794\n","Epoch 48/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.6588\n","Epoch 49/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.6645\n","Epoch 50/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7036\n","Epoch 51/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7096\n","Epoch 52/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.6631\n","Epoch 53/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5733 - accuracy: 0.6847\n","Epoch 54/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.6930\n","Epoch 55/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7398\n","Epoch 56/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.6867\n","Epoch 57/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.6985\n","Epoch 58/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7136\n","Epoch 59/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.6689\n","Epoch 60/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5721 - accuracy: 0.6888\n","Epoch 61/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7032\n","Epoch 62/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7244\n","Epoch 63/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.6866\n","Epoch 64/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.6965\n","Epoch 65/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7133\n","Epoch 66/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5439 - accuracy: 0.7095\n","Epoch 67/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.6993\n","Epoch 68/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.7008\n","Epoch 69/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7160\n","Epoch 70/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.6938\n","Epoch 71/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.6737\n","Epoch 72/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.6936\n","Epoch 73/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.6761\n","Epoch 74/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.6839\n","Epoch 75/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.6875\n","Epoch 76/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.6779\n","Epoch 77/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7010\n","Epoch 78/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.6859\n","Epoch 79/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5381 - accuracy: 0.7036\n","Epoch 80/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.6919\n","Epoch 81/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.6938\n","Epoch 82/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7111\n","Epoch 83/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.7250\n","Epoch 84/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7140\n","Epoch 85/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.6881\n","Epoch 86/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.6621\n","Epoch 87/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.6920\n","Epoch 88/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.6858\n","Epoch 89/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.6927\n","Epoch 90/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7007\n","Epoch 91/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5350 - accuracy: 0.7105\n","Epoch 92/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7275\n","Epoch 93/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.6885\n","Epoch 94/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7508\n","Epoch 95/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7052\n","Epoch 96/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7358\n","Epoch 97/100\n","77/77 [==============================] - 0s 1ms/step - loss: 0.5429 - accuracy: 0.6957\n","Epoch 98/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.6959\n","Epoch 99/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7285\n","Epoch 100/100\n","77/77 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.6845\n","elasped time 12.682463884353638\n","24/24 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.7174\n","\n"," Final Accuracy: 71.74\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LDy08DLKna76","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610753703808,"user_tz":600,"elapsed":27975,"user":{"displayName":"Torrey Wagner","photoUrl":"","userId":"18235062716651285949"}},"outputId":"4879c522-059f-4b75-c1c4-8b62f374fdd5"},"source":["X.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(768, 7)"]},"metadata":{"tags":[]},"execution_count":6}]}]}